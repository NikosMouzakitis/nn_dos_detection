{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUnmchVA1EqTWd/TNpITJa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2C1XSckw-xu","executionInfo":{"status":"ok","timestamp":1733319206842,"user_tz":-120,"elapsed":1523713,"user":{"displayName":"Nikos Mouzakitis","userId":"15455916137485609149"}},"outputId":"8b4982cc-5fab-4473-c8a5-6b9a7b75be08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Start\n","Requirement already satisfied: tensorflow==2.13 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (24.3.25)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.68.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.12.1)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (18.1.1)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.24.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.5.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.16.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13) (0.45.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.2.2)\n","2.13.0\n","Epoch 1/5\n","116326/116326 [==============================] - 275s 2ms/step - loss: 0.1211 - accuracy: 0.9512 - val_loss: 0.0518 - val_accuracy: 0.9817\n","Epoch 2/5\n","116326/116326 [==============================] - 277s 2ms/step - loss: 0.0729 - accuracy: 0.9734 - val_loss: 0.0396 - val_accuracy: 0.9871\n","Epoch 3/5\n","116326/116326 [==============================] - 277s 2ms/step - loss: 0.0617 - accuracy: 0.9781 - val_loss: 0.0350 - val_accuracy: 0.9893\n","Epoch 4/5\n","116326/116326 [==============================] - 271s 2ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0310 - val_accuracy: 0.9904\n","Epoch 5/5\n","116326/116326 [==============================] - 275s 2ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0301 - val_accuracy: 0.9906\n","29082/29082 [==============================] - 40s 1ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.98    197308\n","           1       0.99      1.00      0.99    733300\n","\n","    accuracy                           0.99    930608\n","   macro avg       0.99      0.98      0.99    930608\n","weighted avg       0.99      0.99      0.99    930608\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["\n","# Function to convert a sequence of CAN IDs into a fixed-size vector\n","def extract_features(can_data, window_size=64):\n","    \"\"\"\n","    Converts a sequence of CAN IDs into a fixed-size vector.\n","    :param can_data: List of CAN IDs (e.g., integers or strings)\n","    :param window_size: The size of the sliding window (input length)\n","    :return: A feature vector of length `window_size`\n","    \"\"\"\n","    # Ensure that we have a fixed window size by padding the sequence if it's smaller\n","    # or truncating it if it's larger\n","    if len(can_data) < window_size:\n","        # Padding with 0 (assuming CAN IDs range from 0 to 255)\n","        can_data = [0] * (window_size - len(can_data)) + can_data\n","    elif len(can_data) > window_size:\n","        # Truncating if the sequence is longer than the window size\n","        can_data = can_data[:window_size]\n","\n","    return np.array(can_data)\n","\n","# Create a dataset of normal and intrusion data\n","def create_dataset(normal_can_data, intrusion_can_data, window_size=64):\n","    \"\"\"\n","    Create a dataset for training.\n","    :param normal_can_data: List of CAN IDs for normal traffic\n","    :param intrusion_can_data: List of CAN IDs for intrusion traffic\n","    :param window_size: The size of the sliding window for feature extraction\n","    :return: Tuple of feature array X and label array y\n","    \"\"\"\n","    features = []\n","    labels = []\n","\n","    # Extract features for normal data\n","    for i in range(len(normal_can_data) - window_size + 1):\n","        window_data = normal_can_data[i:i+window_size]\n","        features.append(extract_features(window_data, window_size))\n","        labels.append(0)  # 0 for normal\n","\n","    # Extract features for intrusion data\n","    for i in range(len(intrusion_can_data) - window_size + 1):\n","        window_data = intrusion_can_data[i:i+window_size]\n","        features.append(extract_features(window_data, window_size))\n","        labels.append(1)  # 1 for intrusion\n","\n","    return np.array(features), np.array(labels)\n","\n","# Function to load CAN ID data from a file and remove the first character\n","def load_can_ids_from_file(file_path):\n","    \"\"\"\n","    Loads CAN IDs from a file, removes the first character, and returns them as a list of integers.\n","    :param file_path: Path to the file containing CAN IDs (one per line)\n","    :return: List of CAN IDs as integers\n","    \"\"\"\n","    with open(file_path, 'r') as file:\n","        # For each line, strip it, remove the first character, and convert to integer\n","        can_ids = [int(line.strip()[1:], 16) for line in file.readlines() if line.strip()]\n","    return can_ids\n","\n","\n","\n","print(\"Start\")\n","!pip install tensorflow==2.13\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","print(tf.__version__)\n","\n","\n","\n","# Load normal and intrusion CAN ID data\n","normal_can_data = load_can_ids_from_file('NORMAL_IDS.txt')  # File containing normal CAN IDs\n","intrusion_can_data = load_can_ids_from_file('DOS_IDS.txt')  # File containing intrusion CAN IDs\n","\n","# Create dataset\n","X, y = create_dataset(normal_can_data, intrusion_can_data)\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalize the features (CAN IDs in range 0-255, so normalization is optional but can help)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Define a simple neural network model\n","model = Sequential([\n","    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n","    Dropout(0.2),\n","    Dense(64, activation='relu'),\n","    Dropout(0.2),\n","    Dense(1, activation='sigmoid')  # Binary output (normal or intrusion)\n","])\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n","\n","# Print classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Save the model for future use\n","model.save('can_intrusion_detection_model.h5')\n","\n"]},{"cell_type":"code","source":[" #Assuming NORMAL_IDS.txt contains one CAN ID per line\n","def read_can_data(file_path):\n","    # Read CAN IDs from the file\n","    with open(file_path, 'r') as file:\n","        can_ids = file.readlines()\n","\n","    # Chop the first character from each CAN ID\n","    can_ids = [can_id.strip()[1:] for can_id in can_ids]  # strip() removes newline characters, [1:] removes first character\n","    return can_ids\n","# Function to preprocess the window and convert CAN IDs to numeric\n","def preprocess_window(window, window_size=64):\n","    \"\"\"\n","    Preprocess the window data into the shape (1, window_size).\n","    :param window: List of CAN IDs (e.g., hexadecimal strings)\n","    :param window_size: The size of the sliding window (input length)\n","    :return: A preprocessed feature vector reshaped to (1, window_size)\n","    \"\"\"\n","    # Convert hexadecimal CAN IDs (strings) to integers\n","    window_data = [int(can_id, 16) for can_id in window]\n","\n","    # Ensure the window is fixed size\n","    window_data = extract_features(window_data, window_size)\n","\n","    # Reshape to (1, window_size) for the model\n","    window_data = window_data.reshape(1, window_size)  # Reshape to (1, window_size)\n","\n","    # Normalize the data (assuming scaler is already fitted)\n","    window_data = scaler.transform(window_data)  # Normalize using the same scaler used during training\n","\n","    return window_data\n","\n","def create_windows(can_ids, window_size=64):\n","    # Create sliding windows of data from the can_ids list\n","    windows = []\n","    for i in range(len(can_ids) - window_size + 1):\n","        windows.append(can_ids[i:i + window_size])\n","    return windows\n","\n","\n","\n","\n","intrusion=0\n","normal = 0\n","\n","# Example usage\n","file_path = 'NORMAL_IDS.txt'\n","can_ids = read_can_data(file_path)  # Read and process CAN IDs\n","input_data = create_windows(can_ids[45341:], window_size=64)  # Create windows of size 64\n","\n","# Optionally, print a few windows\n","for window in input_data[:5]:\n","    print(window)\n","\n","for i in range(0,200):\n","   #print(\"Get a prediciton\")\n","    window = input_data[i]  # Get the first window (replace with the desired window)\n","    processed_window = preprocess_window(window)  # Preprocess it\n","\n","    # Get the prediction from the model\n","    prediction = model.predict(processed_window)\n","    #print(f\"Prediction: {prediction}\")\n","    # Interpret the prediction (output is between 0 and 1, where 0 means normal and 1 means intrusion)\n","    if prediction < 0.5:\n"," #       print(\"Prediction: Normal traffic\")\n","        normal+=1\n","    else:\n","#        print(\"Prediction: Intrusion detected\")\n","        intrusion+=1\n","\n","print(\"normal: \"+str(normal))\n","print(\"Intrusion: \"+str(intrusion))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Plaw6Nyc7PM0","executionInfo":{"status":"ok","timestamp":1733320258462,"user_tz":-120,"elapsed":16567,"user":{"displayName":"Nikos Mouzakitis","userId":"15455916137485609149"}},"outputId":"f706026e-0b4b-4877-b6a7-89e32954c9d7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['430', '4b1', '1f1', '153', '002', '130', '131', '140', '18f', '260', '2a0', '2b0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f', '260', '2a0', '329', '350', '545', '43f', '370', '440', '2c0', '430', '4b1', '1f1', '153', '002', '130', '131', '140', '2b0', '18f', '260', '2a0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0']\n","['4b1', '1f1', '153', '002', '130', '131', '140', '18f', '260', '2a0', '2b0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f', '260', '2a0', '329', '350', '545', '43f', '370', '440', '2c0', '430', '4b1', '1f1', '153', '002', '130', '131', '140', '2b0', '18f', '260', '2a0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0']\n","['1f1', '153', '002', '130', '131', '140', '18f', '260', '2a0', '2b0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f', '260', '2a0', '329', '350', '545', '43f', '370', '440', '2c0', '430', '4b1', '1f1', '153', '002', '130', '131', '140', '2b0', '18f', '260', '2a0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316']\n","['153', '002', '130', '131', '140', '18f', '260', '2a0', '2b0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f', '260', '2a0', '329', '350', '545', '43f', '370', '440', '2c0', '430', '4b1', '1f1', '153', '002', '130', '131', '140', '2b0', '18f', '260', '2a0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f']\n","['002', '130', '131', '140', '18f', '260', '2a0', '2b0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f', '260', '2a0', '329', '350', '545', '43f', '370', '440', '2c0', '430', '4b1', '1f1', '153', '002', '130', '131', '140', '2b0', '18f', '260', '2a0', '316', '329', '350', '545', '43f', '370', '440', '2c0', '002', '153', '130', '131', '140', '4f0', '2b0', '316', '18f', '260']\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","normal: 195\n","Intrusion: 5\n"]}]},{"cell_type":"code","source":["# Save the fitted scaler for later use\n","import joblib\n","joblib.dump(scaler, \"scaler.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1elFWY9F7hkY","executionInfo":{"status":"ok","timestamp":1733320819386,"user_tz":-120,"elapsed":315,"user":{"displayName":"Nikos Mouzakitis","userId":"15455916137485609149"}},"outputId":"5426d874-c821-44c1-dbf2-0d68d4757374"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['scaler.pkl']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"K07V9VHg-L94"},"execution_count":null,"outputs":[]}]}